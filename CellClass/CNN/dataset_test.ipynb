{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pickle as pkl\n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, files, pos=\"S19_\", neg=\"S29_\", transform=None):\n",
    "        super().__init__()\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "        self.files = files\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample_name = self.files[idx].split(\"/\")[-1]\n",
    "        true_class = self.get_true_class(sample_name, idx)\n",
    "\n",
    "        with open(self.files[idx], \"rb\") as fin:\n",
    "            patch = pkl.load(fin)\n",
    "            masked = self.get_masked(patch)\n",
    "            \n",
    "            sample = {\"image\": masked,\n",
    "                      \"true_class\": true_class}\n",
    "            \n",
    "            if self.transform:\n",
    "                sample = transform(sample)\n",
    "                \n",
    "            return sample\n",
    "            \n",
    "            \n",
    "    def get_masked(self, patch):\n",
    "        tmp = patch.RGB\n",
    "        tmp[~patch.mask]=0\n",
    "        return tmp\n",
    "    \n",
    "    def get_true_class(self, sample_name, idx):\n",
    "        \n",
    "        if self.pos in sample_name:\n",
    "            label = 1\n",
    "        elif self.neg in sample_name:\n",
    "            label = 0\n",
    "            \n",
    "        return label\n",
    "        \n",
    "class ToTensor():\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, true_class = sample['image'], sample['true_class']        \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'true_class': torch.tensor(true_class)}\n",
    "\n",
    "class RandomAffine():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transformer = transforms.RandomAffine(degrees=(0,360), translate=(0.1, 0.1), scale=(0.9, 1.1), fill=0)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, true_class = sample['image'], sample['true_class'] \n",
    "        \n",
    "        return {'image': self.transformer(image),\n",
    "                'true_class': true_class}\n",
    "  \n",
    "class RandomFlip():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vert = transforms.RandomVerticalFlip()\n",
    "        self.hor = transforms.RandomHorizontalFlip()\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, true_class = sample['image'], sample['true_class'] \n",
    "        \n",
    "        image = self.vert(image)\n",
    "        image = self.hor(image)\n",
    "        \n",
    "        return {'image': image,\n",
    "                'true_class': true_class}\n",
    "       \n",
    "class Normalize():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.means = torch.tensor([0.019045139, 0.033935968, 0.06551865])\n",
    "        self.stds = torch.tensor([0.05771165, 0.11356566, 0.17648968])\n",
    "        self.transformer = transforms.Normalize(self.means, self.stds)\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        \n",
    "        image, true_class = sample['image'], sample['true_class'] \n",
    "        \n",
    "        return {'image': self.transformer(image),\n",
    "                'true_class': true_class}\n",
    "  \n",
    "  \n",
    "class MYCNTrainingSet(Dataset):\n",
    "    \n",
    "    def __init__(self, base, pos=\"S19_\", neg=\"S29_\", split=[0.8, 0.1, 0.1]):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "        self.split = split\n",
    "        self.files = np.array(self._get_files(self.pos) + self._get_files(self.neg))\n",
    "    \n",
    "        assert sum(self.split) == 1, \"Split must sum up to 1\"\n",
    "        \n",
    "        train_files, val_files, test_files = self.get_split_indices()\n",
    "        \n",
    "        self.train_dataset = PatchDataset(train_files)\n",
    "        self.val_dataset = PatchDataset(val_files)\n",
    "        self.test_dataset = PatchDataset(test_files)\n",
    "        \n",
    "    def get_split_indices(self):\n",
    "        \n",
    "        total = len(self.files)\n",
    "        train_num = int(len(self.files)*self.split[0])\n",
    "        val_num = int(len(self.files)*self.split[1])\n",
    "        test_num = len(self.files)-(train_num+val_num)\n",
    "        idxs = list(range(len(self.files)))\n",
    "        random.shuffle(idxs)\n",
    "        \n",
    "        train_idxs = idxs[:train_num]\n",
    "        val_idxs = idxs[train_num:train_num+val_num]\n",
    "        test_idxs = idxs[-test_num:]\n",
    "        \n",
    "        return self.files[train_idxs], self.files[val_idxs], self.files[test_idxs]\n",
    "          \n",
    "    def _get_files(self, pattern):\n",
    "        return [os.path.join(self.base, x) for x in os.listdir(self.base) if pattern in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 128, 128, 3])\n",
      "torch.Size([256, 128, 128, 3])\n",
      "torch.Size([256, 128, 128, 3])\n",
      "torch.Size([256, 128, 128, 3])\n",
      "torch.Size([256, 128, 128, 3])\n",
      "torch.Size([256, 128, 128, 3])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/simon_g/src/MICCAI/CellClass/CNN/dataset_test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bccri/home/simon_g/src/MICCAI/CellClass/CNN/dataset_test.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m im \u001b[39m=\u001b[39m sample[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bccri/home/simon_g/src/MICCAI/CellClass/CNN/dataset_test.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(im\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bccri/home/simon_g/src/MICCAI/CellClass/CNN/dataset_test.ipynb#ch0000001vscode-remote?line=9'>10</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m3\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "base = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/MYCN_SpikeIn/results/single_patches\"\n",
    "transform=transforms.Compose([ToTensor(), RandomAffine(), RandomFlip(), Normalize()])\n",
    "data = MYCNTrainingSet(base)\n",
    "loader = DataLoader(data.train_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "for sample in loader:\n",
    "    im = sample[\"image\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in loader:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/MYCN_SpikeIn/results/patches\"\n",
    "out = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/MYCN_SpikeIn/results/single_patches\"\n",
    "\n",
    "import pickle as pkl\n",
    "for pattern in [\"S19_\", \"S29_\"]:\n",
    "    files = [os.path.join(base, x) for x in os.listdir(base) if pattern in x]\n",
    "    for file in files[:200]:\n",
    "        with open(file, \"rb\") as fin:\n",
    "            n = file.split(\"/\")[-1].split(\".\")[0]\n",
    "            if os.path.isfile(os.path.join(out, f\"{n}_0.ptch\")):\n",
    "                print(n + \" already exists\")\n",
    "                continue\n",
    "            print(n)\n",
    "            dat = pkl.load(fin)\n",
    "            for i, d in enumerate(dat):\n",
    "                with open(os.path.join(out, f\"{n}_{i}.ptch\"), \"wb+\") as fout:\n",
    "                    pkl.dump(d, fout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "out = \"/data_isilon_main/isilon_images/10_MetaSystems/MetaSystemsData/MYCN_SpikeIn/results/single_patches\"\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "images = []\n",
    "masks = []\n",
    "for n, file in enumerate(tqdm(os.listdir(out)[:10000])):\n",
    "    with open(os.path.join(out, file), \"rb\") as fin:\n",
    "        patch = pkl.load(fin)\n",
    "        tmp = patch.RGB\n",
    "        tmp[~patch.mask] = 0\n",
    "        images.append(tmp)\n",
    "\n",
    "    images_arr = np.array(images)\n",
    "    masks_arr = np.array(masks)\n",
    "\n",
    "    R_means = np.mean(images_arr[..., 0])\n",
    "    G_means = np.mean(images_arr[..., 1])\n",
    "    B_means = np.mean(images_arr[..., 2])\n",
    "    R_stds = np.std(images_arr[..., 0])\n",
    "    G_stds = np.std(images_arr[..., 1])\n",
    "    B_stds = np.std(images_arr[..., 2])\n",
    " \n",
    "print(R_means[-1],G_means[-1], B_means[-1], R_stds[-1], G_stds[-1], B_stds[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_mean = np.mean(images[masks, 0])\n",
    "G_mean = np.mean(images[masks, 1])\n",
    "B_mean = np.mean(images[masks, 2])\n",
    "R_std = np.std(images[masks, 0])\n",
    "G_std = np.std(images[masks, 1])\n",
    "B_std = np.std(images[masks, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,10,2,3,4,5,6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CellClass': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ca051f595fd847f563662e2b49599d5cdd463b3fc7629239e736414d44149a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
